{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sohnnick/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from dateutil.parser import parse\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Frame Databases and Obtain Metrics***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('NKE-explore.txt') as f:\n",
    "    nke_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json2df(json_data): \n",
    "    #create empty dictionary\n",
    "    dictdat = {'date':[], 'sentiment':[], 'body':[]}\n",
    "    #append to dictionary\n",
    "    for data in json_data:\n",
    "        if data['sentiment'] != None:\n",
    "            dictdat['sentiment'].append(data['sentiment']['class'])\n",
    "        else:\n",
    "            dictdat['sentiment'].append('None')\n",
    "        dictdat['date'].append(datetime.strptime(data['created_at'][:16], '%a, %d %b %Y'))\n",
    "        dictdat['body'].append(data['body'])\n",
    "    #convert to dataframe\n",
    "    df = pd.DataFrame(data=dictdat).sort_values(by='date').reset_index()\n",
    "    del df['index']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call function\n",
    "text_nke = convert_json2df(nke_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>None</td>\n",
       "      <td>A lot of stocks now trading green:  $GS $WFC $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>None</td>\n",
       "      <td>Nike's EVP &amp; CFO just cashed-in 33,000 options...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2013-12-04</td>\n",
       "      <td>None</td>\n",
       "      <td>China dragged down a lot of giant companies la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2013-12-04</td>\n",
       "      <td>bullish</td>\n",
       "      <td>$NKE Buying the dip.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2013-12-04</td>\n",
       "      <td>None</td>\n",
       "      <td>Drake Signs with Jordan Brand, Kanye with adid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2013-12-04</td>\n",
       "      <td>None</td>\n",
       "      <td>$NKE NIKE Redefines Basketball Footwear with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2013-12-04</td>\n",
       "      <td>None</td>\n",
       "      <td>$NKE gives you a chance to design shoes for Ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>None</td>\n",
       "      <td>On http://stks.co/f00Qo ( http://stks.co/f00Qp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>None</td>\n",
       "      <td>On The Yield Game ( http://stks.co/dx9q ) Now ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>None</td>\n",
       "      <td>$JCP from my profit going to get some $NKE clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>None</td>\n",
       "      <td>\"@Stef540: $JCP from my profit going to get so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>None</td>\n",
       "      <td>Just a Glimpse of Competitive Analysis b/w $NK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>None</td>\n",
       "      <td>$nke actually put on a position looks poised t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>None</td>\n",
       "      <td>In A Yoga Pants Glut, Whatâ€™s lululemon Worth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>None</td>\n",
       "      <td>$NKE NIKE, Inc. Announces Second Quarter Fisca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>bullish</td>\n",
       "      <td>$NKE After Hours: 79.19 +0.24 (0.30%) Dec 5, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2013-12-06</td>\n",
       "      <td>None</td>\n",
       "      <td>$NKE will this time be different ?  http://stk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2013-12-06</td>\n",
       "      <td>None</td>\n",
       "      <td>$NKE $AAPL $DIS culture of perfection. better ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2013-12-07</td>\n",
       "      <td>None</td>\n",
       "      <td>$NKE http://stks.co/pieF &amp;lt; interesting Wedg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2013-12-07</td>\n",
       "      <td>None</td>\n",
       "      <td>$NKE I think they are getting tired &amp; old on t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date sentiment                                               body\n",
       "0  2013-12-03      None  A lot of stocks now trading green:  $GS $WFC $...\n",
       "1  2013-12-03      None  Nike's EVP & CFO just cashed-in 33,000 options...\n",
       "2  2013-12-04      None  China dragged down a lot of giant companies la...\n",
       "3  2013-12-04   bullish                               $NKE Buying the dip.\n",
       "4  2013-12-04      None  Drake Signs with Jordan Brand, Kanye with adid...\n",
       "5  2013-12-04      None  $NKE NIKE Redefines Basketball Footwear with t...\n",
       "6  2013-12-04      None  $NKE gives you a chance to design shoes for Ti...\n",
       "7  2013-12-05      None  On http://stks.co/f00Qo ( http://stks.co/f00Qp...\n",
       "8  2013-12-05      None  On The Yield Game ( http://stks.co/dx9q ) Now ...\n",
       "9  2013-12-05      None  $JCP from my profit going to get some $NKE clo...\n",
       "10 2013-12-05      None  \"@Stef540: $JCP from my profit going to get so...\n",
       "11 2013-12-05      None  Just a Glimpse of Competitive Analysis b/w $NK...\n",
       "12 2013-12-05      None  $nke actually put on a position looks poised t...\n",
       "13 2013-12-05      None  In A Yoga Pants Glut, Whatâ€™s lululemon Worth...\n",
       "14 2013-12-05      None  $NKE NIKE, Inc. Announces Second Quarter Fisca...\n",
       "15 2013-12-05   bullish  $NKE After Hours: 79.19 +0.24 (0.30%) Dec 5, 5...\n",
       "16 2013-12-06      None  $NKE will this time be different ?  http://stk...\n",
       "17 2013-12-06      None  $NKE $AAPL $DIS culture of perfection. better ...\n",
       "18 2013-12-07      None  $NKE http://stks.co/pieF &lt; interesting Wedg...\n",
       "19 2013-12-07      None  $NKE I think they are getting tired & old on t..."
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_nke.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_metrics(df):\n",
    "    #obtain unique dates\n",
    "    date_list = list(set(list(df['date'])))\n",
    "    len(date_list)\n",
    "    date_list.sort()\n",
    "    \n",
    "    #group data\n",
    "    grouped_df = df.groupby('date')\n",
    "    \n",
    "    #obtain polarity, message volume, 1-day volume change, 10-day likelihood\n",
    "    polarity_list = []\n",
    "    volume_list = []\n",
    "    vchange1 = []\n",
    "    vchange10 = []\n",
    "    polarity_movaverage = []\n",
    "    for i in range(0, len(date_list)):\n",
    "        date_temp = grouped_df.get_group(date_list[i])\n",
    "        date_temp = list(date_temp['sentiment'])\n",
    "        polarity = (date_temp.count('bullish')-date_temp.count('bearish'))/len(date_temp)\n",
    "        polarity_list.append(polarity)\n",
    "        volume_list.append(len(date_temp))\n",
    "        if i == 0:\n",
    "            vchange1.append(None)\n",
    "        else:\n",
    "            day1change = (volume_list[i]-volume_list[i-1])/volume_list[i-1]\n",
    "            vchange1.append(day1change)\n",
    "        if i < 10:\n",
    "            vchange10.append(None)\n",
    "        else:\n",
    "            day10change = len(date_temp)/(sum(volume_list[i-10:i])/10)\n",
    "            vchange10.append(day10change)\n",
    "        if i >= 2:\n",
    "            movave = (polarity_list[i] + polarity_list[i-1] + polarity_list[i-2])/3\n",
    "            polarity_movaverage.append(movave)\n",
    "        else:\n",
    "            polarity_movaverage.append(None)\n",
    "    \n",
    "    #create a dataframe with the results\n",
    "    date_metrics_dict = {}\n",
    "    date_metrics_dict['date'] = date_list\n",
    "    date_metrics_dict['polarity'] = polarity_list\n",
    "    date_metrics_dict['st'] = polarity_movaverage\n",
    "    date_metrics_dict['msgvolume'] = volume_list\n",
    "    date_metrics_dict['mv1t'] = vchange1\n",
    "    date_metrics_dict['mv10t'] = vchange10\n",
    "    df_final = pd.DataFrame(data=date_metrics_dict)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>polarity</th>\n",
       "      <th>st</th>\n",
       "      <th>msgvolume</th>\n",
       "      <th>mv1t</th>\n",
       "      <th>mv10t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2013-12-04</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.103704</td>\n",
       "      <td>9</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2013-12-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103704</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2013-12-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2013-12-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2013-12-09</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>9</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2013-12-10</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.231481</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2013-12-11</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.256173</td>\n",
       "      <td>27</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2013-12-12</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.241358</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.814815</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2013-12-13</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.232099</td>\n",
       "      <td>9</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.267606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2013-12-14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207407</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>0.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2013-12-15</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.216931</td>\n",
       "      <td>7</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2013-12-16</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2013-12-17</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.273810</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2013-12-18</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>12</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.481481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2013-12-19</td>\n",
       "      <td>0.131313</td>\n",
       "      <td>0.210438</td>\n",
       "      <td>99</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>11.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2013-12-20</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.187710</td>\n",
       "      <td>77</td>\n",
       "      <td>-0.222222</td>\n",
       "      <td>4.325843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2013-12-22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104377</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.948052</td>\n",
       "      <td>0.159363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2013-12-23</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.203463</td>\n",
       "      <td>7</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.307018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  polarity        st  msgvolume      mv1t      mv10t\n",
       "0  2013-12-03  0.000000       NaN          2       NaN        NaN\n",
       "1  2013-12-04  0.200000       NaN          5  1.500000        NaN\n",
       "2  2013-12-05  0.111111  0.103704          9  0.800000        NaN\n",
       "3  2013-12-06  0.000000  0.103704          2 -0.777778        NaN\n",
       "4  2013-12-07  0.000000  0.037037          3  0.500000        NaN\n",
       "5  2013-12-08  0.000000  0.000000          5  0.666667        NaN\n",
       "6  2013-12-09  0.444444  0.148148          9  0.800000        NaN\n",
       "7  2013-12-10  0.250000  0.231481          4 -0.555556        NaN\n",
       "8  2013-12-11  0.074074  0.256173         27  5.750000        NaN\n",
       "9  2013-12-12  0.400000  0.241358          5 -0.814815        NaN\n",
       "10 2013-12-13  0.222222  0.232099          9  0.800000   1.267606\n",
       "11 2013-12-14  0.000000  0.207407          4 -0.555556   0.512821\n",
       "12 2013-12-15  0.428571  0.216931          7  0.750000   0.909091\n",
       "13 2013-12-16  0.142857  0.190476          7  0.000000   0.933333\n",
       "14 2013-12-17  0.250000  0.273810          4 -0.428571   0.500000\n",
       "15 2013-12-18  0.250000  0.214286         12  2.000000   1.481481\n",
       "16 2013-12-19  0.131313  0.210438         99  7.250000  11.250000\n",
       "17 2013-12-20  0.181818  0.187710         77 -0.222222   4.325843\n",
       "18 2013-12-22  0.000000  0.104377          4 -0.948052   0.159363\n",
       "19 2013-12-23  0.428571  0.203463          7  0.750000   0.307018"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "df_volume = obtain_metrics(text_nke)\n",
    "df_volume.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_price = pd.read_csv('NKE-explore.csv')\n",
    "df_price = df_price.sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_target(df_price):\n",
    "    length = len(df_price)\n",
    "    #only interested in the closing price\n",
    "    close = list(df_price['CLOSE'])\n",
    "    rt3 = []\n",
    "    rt5 = []\n",
    "    for i in range(0,length):\n",
    "        if i > length-4:\n",
    "            rt3.append(None)\n",
    "        else:\n",
    "            temp_3 = (close[i+3]-close[i])/close[i]\n",
    "            rt3.append(temp_3)\n",
    "        if i > length-6:\n",
    "            rt5.append(None)\n",
    "        else:\n",
    "            temp_5 = (close[i+5]-close[i])/close[i]\n",
    "            rt5.append(temp_5)\n",
    "    \n",
    "    prediction_dict = {}\n",
    "    prediction_dict['rt3'] = rt3\n",
    "    prediction_dict['rt5'] = rt5\n",
    "    return prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call function to obtain forward T day return\n",
    "df_prediction = prediction_target(df_price)\n",
    "df_prediction = pd.DataFrame(data=df_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>rt3</th>\n",
       "      <th>rt5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-26</td>\n",
       "      <td>30.810515</td>\n",
       "      <td>30.968887</td>\n",
       "      <td>30.676139</td>\n",
       "      <td>5472400</td>\n",
       "      <td>30.676139</td>\n",
       "      <td>-0.003582</td>\n",
       "      <td>0.009133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-27</td>\n",
       "      <td>30.359395</td>\n",
       "      <td>30.589756</td>\n",
       "      <td>30.133837</td>\n",
       "      <td>4870800</td>\n",
       "      <td>30.143435</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>0.040384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2013-08-28</td>\n",
       "      <td>30.100242</td>\n",
       "      <td>30.570559</td>\n",
       "      <td>30.066649</td>\n",
       "      <td>6044000</td>\n",
       "      <td>30.412186</td>\n",
       "      <td>0.017891</td>\n",
       "      <td>0.035149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2013-08-29</td>\n",
       "      <td>30.330330</td>\n",
       "      <td>30.749243</td>\n",
       "      <td>30.277363</td>\n",
       "      <td>4600000</td>\n",
       "      <td>30.566269</td>\n",
       "      <td>0.025992</td>\n",
       "      <td>0.023630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2013-08-30</td>\n",
       "      <td>30.677016</td>\n",
       "      <td>30.715537</td>\n",
       "      <td>30.142539</td>\n",
       "      <td>5851000</td>\n",
       "      <td>30.248472</td>\n",
       "      <td>0.040751</td>\n",
       "      <td>0.041070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>823</td>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>50.338380</td>\n",
       "      <td>50.627339</td>\n",
       "      <td>49.889998</td>\n",
       "      <td>8198400</td>\n",
       "      <td>49.889998</td>\n",
       "      <td>0.039286</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>824</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>50.110001</td>\n",
       "      <td>51.250000</td>\n",
       "      <td>50.060001</td>\n",
       "      <td>7610100</td>\n",
       "      <td>50.650002</td>\n",
       "      <td>-0.001580</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2016-12-02</td>\n",
       "      <td>50.259998</td>\n",
       "      <td>50.680000</td>\n",
       "      <td>50.110001</td>\n",
       "      <td>6730200</td>\n",
       "      <td>50.459999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>826</td>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>50.799999</td>\n",
       "      <td>52.270000</td>\n",
       "      <td>50.700001</td>\n",
       "      <td>11995300</td>\n",
       "      <td>51.849998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>827</td>\n",
       "      <td>2016-12-06</td>\n",
       "      <td>50.830002</td>\n",
       "      <td>51.099998</td>\n",
       "      <td>50.259998</td>\n",
       "      <td>12411900</td>\n",
       "      <td>50.570000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>828 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       OPEN       HIGH        LOW    VOLUME      CLOSE  \\\n",
       "0    2013-08-26  30.810515  30.968887  30.676139   5472400  30.676139   \n",
       "1    2013-08-27  30.359395  30.589756  30.133837   4870800  30.143435   \n",
       "2    2013-08-28  30.100242  30.570559  30.066649   6044000  30.412186   \n",
       "3    2013-08-29  30.330330  30.749243  30.277363   4600000  30.566269   \n",
       "4    2013-08-30  30.677016  30.715537  30.142539   5851000  30.248472   \n",
       "..          ...        ...        ...        ...       ...        ...   \n",
       "823  2016-11-30  50.338380  50.627339  49.889998   8198400  49.889998   \n",
       "824  2016-12-01  50.110001  51.250000  50.060001   7610100  50.650002   \n",
       "825  2016-12-02  50.259998  50.680000  50.110001   6730200  50.459999   \n",
       "826  2016-12-05  50.799999  52.270000  50.700001  11995300  51.849998   \n",
       "827  2016-12-06  50.830002  51.099998  50.259998  12411900  50.570000   \n",
       "\n",
       "          rt3       rt5  \n",
       "0   -0.003582  0.009133  \n",
       "1    0.003485  0.040384  \n",
       "2    0.017891  0.035149  \n",
       "3    0.025992  0.023630  \n",
       "4    0.040751  0.041070  \n",
       "..        ...       ...  \n",
       "823  0.039286       NaN  \n",
       "824 -0.001580       NaN  \n",
       "825       NaN       NaN  \n",
       "826       NaN       NaN  \n",
       "827       NaN       NaN  \n",
       "\n",
       "[828 rows x 8 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metricsandvalue = pd.concat([df_price, df_prediction], axis=1)\n",
    "df_metricsandvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Pre Processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of characters/tickers to remove\n",
    "list_of_symbols = pd.read_csv('constituents_csv.csv')\n",
    "remove = list(list_of_symbols['Symbol'])\n",
    "temp = list('{}()[].,:;+-*/&|<>=~@#$?%!&*')\n",
    "#manually add some symbols/characters that should be removed\n",
    "remove1 = ['http', '\\'s', '``', '\\'\\'', '...', '--', '..', 'puc=yahoo', 'cm_ven=YAHOO',\n",
    "          'yptr=yahoo', '//dividendvaluebuilder.com/nike-nke-dividend-stock-analysis/',\n",
    "          'utm_medium=eps_update', '//marketrealist.com/', 'n\\'t', 'utm_source=stocktwits',\n",
    "          '//www.estimize.com/intro/nke', 'utm_content=NKE', 'chart=historical', '\\'',\n",
    "          '\\'m', 'utm_medium=reporting_this_week_consensus', '//simplywall.st/NYSE',\n",
    "          'utm_medium=stocktwits', '//link.scoutfin.com/8gyk/SHiJ2vhB2t', 'nke', 'Nike', 'I',\n",
    "          '//bit.ly/TTSNKE', 'chart=scatter-plot', 'past-future-earnings', 'anchor=past-future-earnings']\n",
    "remove = remove + temp + remove1\n",
    "#print(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def list_of_words(text):\n",
    "    body = list(text['body'])\n",
    "    wordlist = []\n",
    "    for i in range(0, len(body)):\n",
    "        text = body[i]\n",
    "        text_tokens = word_tokenize(text)\n",
    "        wordlist = wordlist + text_tokens\n",
    "    return wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = list_of_words(text_nke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565316"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to check if string is a date\n",
    "def is_date(string, fuzzy=False):\n",
    "    try: \n",
    "        parse(string, fuzzy=fuzzy)\n",
    "        return True\n",
    "\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary and filter the keys\n",
    "def word_dictionary(wordlist):\n",
    "    word_dict = {}\n",
    "    #get counts for each unique word word\n",
    "    for i in range(0, len(wordlist)):\n",
    "        if wordlist[i] in word_dict:\n",
    "            word_dict[wordlist[i]] = word_dict.get(wordlist[i])+1\n",
    "        else:\n",
    "            word_dict[wordlist[i]] = 1\n",
    "    print('total unique words:', len(word_dict.keys()))\n",
    "    \n",
    "    #filter the words\n",
    "    keys = list(word_dict.keys())\n",
    "    for i in keys:\n",
    "        #remove word if it appears less than 25 times\n",
    "        if word_dict.get(i) < 25:\n",
    "            del word_dict[i]\n",
    "        #remove word if it is a stopword\n",
    "        elif i in stopwords.words():\n",
    "            del word_dict[i]\n",
    "        #remove word if it falls under the words to remove listed above\n",
    "        elif i in remove:\n",
    "            del word_dict[i]\n",
    "        elif is_date(i) == True:\n",
    "            del word_dict[i]\n",
    "        elif i.isnumeric() == True:\n",
    "            del word_dict[i]\n",
    "    print('total unique words after filtering:', len(word_dict))\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique words: 37828\n",
      "total unique words after filtering: 1482\n"
     ]
    }
   ],
   "source": [
    "word_dict = word_dictionary(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('earnings', 1403),\n",
       " ('today', 1262),\n",
       " ('buy', 1218),\n",
       " ('like', 1013),\n",
       " ('SPY', 913),\n",
       " ('stock', 854),\n",
       " ('good', 831),\n",
       " ('long', 813),\n",
       " ('The', 744),\n",
       " ('EPS', 730),\n",
       " ('Estimize', 715),\n",
       " ('market', 706),\n",
       " ('going', 678),\n",
       " ('AMC', 659),\n",
       " ('see', 636),\n",
       " ('stocks', 623),\n",
       " ('week', 622),\n",
       " ('back', 611),\n",
       " ('time', 604),\n",
       " ('tomorrow', 600),\n",
       " ('short', 589),\n",
       " ('get', 588),\n",
       " ('go', 581),\n",
       " ('next', 578),\n",
       " ('Reporting', 571),\n",
       " ('Earnings', 569),\n",
       " ('calls', 562),\n",
       " ('day', 559),\n",
       " ('Stock', 559),\n",
       " ('growth', 555),\n",
       " ('LULU', 534),\n",
       " ('price', 532),\n",
       " ('ER', 525),\n",
       " ('https', 511),\n",
       " ('higher', 484),\n",
       " ('FIT', 478),\n",
       " ('last', 470),\n",
       " ('This', 460),\n",
       " ('Q1', 460),\n",
       " ('would', 456),\n",
       " ('PT', 451),\n",
       " ('SKX', 449),\n",
       " ('’', 444),\n",
       " ('sell', 440),\n",
       " ('New', 437),\n",
       " ('Stocks', 435),\n",
       " ('close', 428),\n",
       " ('new', 426),\n",
       " ('It', 423),\n",
       " ('Here', 421),\n",
       " ('shares', 419),\n",
       " ('report', 419),\n",
       " ('NIKE', 417),\n",
       " ('gt', 417),\n",
       " ('Under', 412),\n",
       " ('still', 407),\n",
       " ('rating', 401),\n",
       " ('think', 399),\n",
       " ('analysts', 392),\n",
       " ('Is', 378),\n",
       " ('Armour', 377),\n",
       " ('revenue', 376),\n",
       " ('FL', 373),\n",
       " ('Just', 363),\n",
       " ('Buy', 363),\n",
       " ('chart', 363),\n",
       " ('high', 360),\n",
       " ('Street', 354),\n",
       " ('position', 347),\n",
       " ('year', 347),\n",
       " ('move', 343),\n",
       " ('big', 342),\n",
       " ('bullish', 341),\n",
       " ('buying', 340),\n",
       " ('nice', 338),\n",
       " ('Wall', 337),\n",
       " ('strong', 336),\n",
       " ('bought', 335),\n",
       " ('call', 334),\n",
       " ('great', 334),\n",
       " ('looking', 331),\n",
       " ('Q2', 324),\n",
       " ('watch', 323),\n",
       " ('believe', 320),\n",
       " ('What', 310),\n",
       " ('trade', 310),\n",
       " ('well', 306),\n",
       " ('look', 301),\n",
       " ('hold', 300),\n",
       " ('shoes', 295),\n",
       " ('Will', 294),\n",
       " ('could', 290),\n",
       " ('target', 290),\n",
       " ('much', 290),\n",
       " ('right', 289),\n",
       " ('money', 288),\n",
       " ('TSLA', 287),\n",
       " ('nike', 286),\n",
       " ('beat', 284),\n",
       " ('looks', 283),\n",
       " ('If', 283),\n",
       " ('Today', 282),\n",
       " ('got', 277),\n",
       " ('coming', 277),\n",
       " ('expectations', 276),\n",
       " ('In', 274),\n",
       " ('support', 273),\n",
       " ('options', 271),\n",
       " ('low', 271),\n",
       " ('sold', 270),\n",
       " ('years', 269),\n",
       " ('Market', 269),\n",
       " ('trading', 264),\n",
       " ('lol', 262),\n",
       " ('make', 257),\n",
       " ('break', 252),\n",
       " ('soon', 251),\n",
       " ('China', 250),\n",
       " ('days', 250),\n",
       " ('know', 244),\n",
       " ('split', 244),\n",
       " ('To', 239),\n",
       " ('Top', 238),\n",
       " ('top', 236),\n",
       " ('way', 236),\n",
       " ('green', 235),\n",
       " ('even', 235),\n",
       " ('puts', 233),\n",
       " ('holding', 231),\n",
       " ('term', 230),\n",
       " ('run', 226),\n",
       " ('No', 226),\n",
       " (\"'ll\", 226),\n",
       " ('Why', 225),\n",
       " ('Watch', 224),\n",
       " ('lower', 224),\n",
       " ('QQQ', 222),\n",
       " ('people', 222),\n",
       " ('better', 221),\n",
       " ('Time', 221),\n",
       " ('BABA', 221),\n",
       " ('Adidas', 220),\n",
       " ('GPRO', 218),\n",
       " ('FINL', 217),\n",
       " ('company', 214),\n",
       " ('AH', 213),\n",
       " ('Chart', 213),\n",
       " ('reiterated', 212),\n",
       " ('around', 211),\n",
       " ('selling', 211),\n",
       " ('vs', 209),\n",
       " ('bounce', 209),\n",
       " ('Up', 209),\n",
       " ('sales', 206),\n",
       " ('since', 205),\n",
       " ('For', 204),\n",
       " ('How', 203),\n",
       " ('morning', 203),\n",
       " ('Trading', 202),\n",
       " ('Long', 202),\n",
       " ('put', 201),\n",
       " ('open', 201),\n",
       " ('ADDYY', 201),\n",
       " ('On', 200),\n",
       " ('play', 198),\n",
       " ('Do', 198),\n",
       " ('Dow', 198),\n",
       " ('profit', 195),\n",
       " ('hit', 194),\n",
       " ('yesterday', 192),\n",
       " ('You', 191),\n",
       " ('volume', 191),\n",
       " ('getting', 189),\n",
       " ('need', 189),\n",
       " ('And', 188),\n",
       " ('Good', 186),\n",
       " ('bad', 186),\n",
       " ('quarter', 185),\n",
       " ('added', 185),\n",
       " ('drop', 178),\n",
       " ('Q4', 178),\n",
       " ('share', 177),\n",
       " ('SPX', 176),\n",
       " ('gap', 176),\n",
       " ('news', 174),\n",
       " ('Inc', 172),\n",
       " ('Not', 171),\n",
       " ('really', 171),\n",
       " ('reports', 170),\n",
       " ('goes', 170),\n",
       " ('STUDY', 169),\n",
       " ('Price', 169),\n",
       " ('highs', 167),\n",
       " ('analyst', 167),\n",
       " ('M', 164),\n",
       " ('P', 164),\n",
       " ('resistance', 162),\n",
       " ('Nice', 162),\n",
       " ('signal', 162),\n",
       " ('BUY', 161),\n",
       " ('DJIA', 160),\n",
       " ('But', 159),\n",
       " ('raised', 159),\n",
       " ('another', 159),\n",
       " ('Cramer', 158),\n",
       " ('wait', 157),\n",
       " ('love', 156),\n",
       " ('RHT', 156),\n",
       " ('guidance', 156),\n",
       " ('expecting', 155),\n",
       " ('Bullish', 155),\n",
       " ('All', 155),\n",
       " ('add', 155),\n",
       " ('weekly', 154),\n",
       " ('Consumer', 154),\n",
       " ('Of', 151),\n",
       " ('might', 148),\n",
       " ('Apparel', 148),\n",
       " ('Apple', 146),\n",
       " ('keep', 145),\n",
       " ('retail', 145),\n",
       " ('BBRY', 143),\n",
       " ('thing', 143),\n",
       " ('say', 143),\n",
       " ('bottom', 142),\n",
       " ('CELG', 142),\n",
       " ('Looking', 140),\n",
       " ('future', 139),\n",
       " ('Best', 139),\n",
       " ('We', 138),\n",
       " ('My', 137),\n",
       " ('breakout', 137),\n",
       " ('best', 136),\n",
       " ('With', 136),\n",
       " ('That', 136),\n",
       " ('Should', 136),\n",
       " ('daily', 135),\n",
       " ('KORS', 135),\n",
       " ('Still', 135),\n",
       " ('little', 134),\n",
       " ('many', 134),\n",
       " ('yet', 134),\n",
       " ('wow', 134),\n",
       " ('DIA', 133),\n",
       " ('via', 132),\n",
       " ('YoY', 132),\n",
       " ('stop', 132),\n",
       " ('miss', 131),\n",
       " ('vs.', 131),\n",
       " ('So', 131),\n",
       " ('far', 130),\n",
       " ('lot', 129),\n",
       " ('Great', 129),\n",
       " ('trend', 129),\n",
       " ('results', 128),\n",
       " ('Short', 128),\n",
       " ('past', 128),\n",
       " ('After', 127),\n",
       " ('Analysts', 127),\n",
       " ('watching', 127),\n",
       " ('PLUG', 127),\n",
       " ('always', 127),\n",
       " ('bearish', 127),\n",
       " (\"'re\", 126),\n",
       " ('Revenue', 125),\n",
       " ('point', 125),\n",
       " ('Olympics', 124),\n",
       " ('expect', 124),\n",
       " ('portfolio', 124),\n",
       " ('dip', 123),\n",
       " ('ua', 123),\n",
       " ('orders', 123),\n",
       " ('red', 123),\n",
       " ('Calls', 123),\n",
       " ('Sell', 123),\n",
       " ('Trade', 123),\n",
       " ('huge', 122),\n",
       " ('Target', 122),\n",
       " ('ago', 122),\n",
       " ('let', 121),\n",
       " ('hours', 121),\n",
       " ('entry', 120),\n",
       " ('action', 120),\n",
       " ('Call', 120),\n",
       " ('shorts', 120),\n",
       " ('They', 120),\n",
       " ('recent', 119),\n",
       " ('brand', 119),\n",
       " ('S', 119),\n",
       " ('level', 118),\n",
       " ('everyone', 118),\n",
       " ('start', 117),\n",
       " ('sure', 117),\n",
       " ('weeks', 116),\n",
       " ('estimates', 116),\n",
       " ('gon', 116),\n",
       " ('Strength', 116),\n",
       " ('Now', 115),\n",
       " ('Big', 115),\n",
       " ('Curry', 115),\n",
       " ('pop', 114),\n",
       " (\"'ve\", 114),\n",
       " ('positive', 114),\n",
       " ('aapl', 114),\n",
       " ('every', 114),\n",
       " ('hope', 114),\n",
       " ('Week', 113),\n",
       " ('months', 113),\n",
       " ('sector', 113),\n",
       " ('RSI', 112),\n",
       " ('trades', 112),\n",
       " ('Looks', 112),\n",
       " ('anyone', 112),\n",
       " ('list', 112),\n",
       " ('created', 112),\n",
       " ('never', 111),\n",
       " ('opportunity', 111),\n",
       " ('Review', 111),\n",
       " ('Inc.', 111),\n",
       " ('Analyst', 111),\n",
       " ('already', 111),\n",
       " ('VRX', 111),\n",
       " ('first', 110),\n",
       " ('guys', 110),\n",
       " ('post', 110),\n",
       " ('E2', 110),\n",
       " ('ahead', 109),\n",
       " ('waiting', 109),\n",
       " ('ALERT', 109),\n",
       " ('CNBC', 109),\n",
       " ('average', 108),\n",
       " ('Growth', 108),\n",
       " ('moving', 108),\n",
       " ('Reports', 108),\n",
       " ('IWM', 108),\n",
       " ('longs', 108),\n",
       " ('Are', 106),\n",
       " ('High', 106),\n",
       " ('dollar', 106),\n",
       " ('us', 105),\n",
       " ('swing', 104),\n",
       " ('made', 104),\n",
       " ('worth', 104),\n",
       " ('rally', 104),\n",
       " ('line', 103),\n",
       " ('said', 103),\n",
       " ('month', 103),\n",
       " ('Its', 103),\n",
       " ('weak', 103),\n",
       " ('Form', 102),\n",
       " ('change', 102),\n",
       " ('Can', 102),\n",
       " ('apparel', 101),\n",
       " ('Down', 101),\n",
       " ('taking', 101),\n",
       " ('estimate', 101),\n",
       " ('charts', 101),\n",
       " ('ready', 101),\n",
       " ('bit', 100),\n",
       " ('deal', 100),\n",
       " ('BBBY', 100),\n",
       " ('Direction', 100),\n",
       " ('companies', 99),\n",
       " ('Notable', 99),\n",
       " ('Weekend', 99),\n",
       " ('Jordan', 98),\n",
       " ('Bought', 98),\n",
       " ('needs', 98),\n",
       " ('Ahead', 98),\n",
       " ('Durables', 98),\n",
       " ('beats', 97),\n",
       " ('missed', 97),\n",
       " ('consumer', 97),\n",
       " ('NBA', 97),\n",
       " ('Watchlist', 96),\n",
       " ('upside', 96),\n",
       " ('gain', 96),\n",
       " ('though', 96),\n",
       " ('option', 95),\n",
       " ('dividend', 94),\n",
       " ('cash', 94),\n",
       " ('seems', 94),\n",
       " ('small', 94),\n",
       " ('range', 94),\n",
       " ('US', 94),\n",
       " ('More', 94),\n",
       " ('StockTwits', 93),\n",
       " ('profits', 92),\n",
       " ('tonight', 92),\n",
       " ('Look', 92),\n",
       " ('real', 91),\n",
       " ('solid', 91),\n",
       " ('As', 91),\n",
       " ('Day', 91),\n",
       " ('Some', 91),\n",
       " ('near', 91),\n",
       " ('win', 91),\n",
       " ('SEC', 90),\n",
       " ('reason', 89),\n",
       " ('Let', 89),\n",
       " ('ANF', 89),\n",
       " ('buyout', 89),\n",
       " ('Most', 89),\n",
       " ('Scan', 89),\n",
       " ('DKS', 88),\n",
       " ('rate', 88),\n",
       " ('fall', 88),\n",
       " ('investors', 88),\n",
       " ('Have', 88),\n",
       " ('CEO', 88),\n",
       " ('went', 87),\n",
       " ('Last', 87),\n",
       " ('Watching', 87),\n",
       " ('gains', 87),\n",
       " ('guess', 87),\n",
       " ('two', 86),\n",
       " ('shoe', 86),\n",
       " ('Could', 86),\n",
       " ('Revs', 85),\n",
       " ('AA', 85),\n",
       " ('names', 85),\n",
       " ('continue', 85),\n",
       " ('From', 85),\n",
       " ('XLY', 85),\n",
       " ('making', 85),\n",
       " ('KBH', 84),\n",
       " ('due', 84),\n",
       " ('lows', 84),\n",
       " ('says', 84),\n",
       " ('Sales', 84),\n",
       " ('current', 84),\n",
       " ('Be', 84),\n",
       " ('interesting', 83),\n",
       " ('maybe', 83),\n",
       " ('PCLN', 83),\n",
       " ('Sold', 83),\n",
       " ('gets', 83),\n",
       " ('Bank', 83),\n",
       " ('Daily', 83),\n",
       " ('give', 83),\n",
       " ('USO', 83),\n",
       " ('Analysis', 82),\n",
       " ('almost', 82),\n",
       " ('earning', 82),\n",
       " ('loss', 82),\n",
       " ('NEW', 82),\n",
       " ('idea', 82),\n",
       " ('Next', 81),\n",
       " ('Dividend', 81),\n",
       " ('early', 81),\n",
       " ('potential', 81),\n",
       " ('pretty', 81),\n",
       " ('Report', 81),\n",
       " ('double', 81),\n",
       " ('lets', 81),\n",
       " ('Puts', 81),\n",
       " ('Filing', 81),\n",
       " ('world', 80),\n",
       " ('running', 80),\n",
       " ('levels', 80),\n",
       " ('These', 80),\n",
       " ('Put', 80),\n",
       " ('Downgrades', 80),\n",
       " ('trying', 79),\n",
       " ('pull', 79),\n",
       " ('markets', 79),\n",
       " ('LOL', 79),\n",
       " ('Going', 79),\n",
       " ('JWN', 79),\n",
       " ('IBB', 79),\n",
       " ('numbers', 79),\n",
       " ('ratings', 79),\n",
       " ('Alert', 79),\n",
       " ('took', 78),\n",
       " ('Money', 78),\n",
       " ('stay', 78),\n",
       " ('See', 78),\n",
       " ('bull', 78),\n",
       " ('video', 78),\n",
       " ('opening', 78),\n",
       " ('risk', 77),\n",
       " ('howardlindzon', 77),\n",
       " ('Get', 77),\n",
       " ('set', 77),\n",
       " ('Check', 77),\n",
       " ('DECK', 76),\n",
       " ('Holding', 76),\n",
       " ('easy', 76),\n",
       " ('Largest', 76),\n",
       " ('Jim', 76),\n",
       " ('Unusual', 76),\n",
       " ('must', 76),\n",
       " ('cheap', 75),\n",
       " ('Movers', 75),\n",
       " ('oversold', 75),\n",
       " ('Who', 75),\n",
       " ('value', 75),\n",
       " ('lost', 75),\n",
       " ('LeBron', 74),\n",
       " ('probably', 74),\n",
       " ('prices', 74),\n",
       " ('season', 74),\n",
       " ('positions', 74),\n",
       " ('sneakers', 74),\n",
       " ('Has', 74),\n",
       " ('Piper', 74),\n",
       " ('performance', 74),\n",
       " ('fill', 74),\n",
       " ('etc', 73),\n",
       " ('half', 73),\n",
       " ('When', 73),\n",
       " ('wrong', 73),\n",
       " ('JBoorman', 73),\n",
       " ('MACD', 73),\n",
       " ('Activity', 73),\n",
       " ('Back', 72),\n",
       " ('w/', 72),\n",
       " ('Rev', 72),\n",
       " ('Q3', 72),\n",
       " ('investing', 72),\n",
       " ('ever', 72),\n",
       " ('closed', 72),\n",
       " ('SUNE', 72),\n",
       " ('please', 72),\n",
       " ('appears', 72),\n",
       " ('game', 71),\n",
       " ('interest', 71),\n",
       " ('Results', 71),\n",
       " ('At', 71),\n",
       " ('Video', 71),\n",
       " ('BIDU', 70),\n",
       " ('billion', 70),\n",
       " ('cents', 70),\n",
       " ('Weekly', 70),\n",
       " ('Investors', 70),\n",
       " ('expiring', 70),\n",
       " ('POST', 70),\n",
       " ('feel', 70),\n",
       " ('breaking', 70),\n",
       " ('bear', 70),\n",
       " ('KKD', 70),\n",
       " ('available', 70),\n",
       " ('JCP', 69),\n",
       " ('Est', 69),\n",
       " ('Strong', 69),\n",
       " ('Out', 69),\n",
       " ('help', 69),\n",
       " ('Future', 69),\n",
       " ('makes', 69),\n",
       " ('analysis', 69),\n",
       " ('follow', 68),\n",
       " ('rise', 68),\n",
       " ('Consensus', 68),\n",
       " ('reversal', 68),\n",
       " ('setup', 68),\n",
       " ('Any', 67),\n",
       " ('hard', 67),\n",
       " ('happened', 67),\n",
       " ('done', 67),\n",
       " ('nothing', 67),\n",
       " ('starting', 67),\n",
       " ('away', 67),\n",
       " ('List', 67),\n",
       " ('Lebron', 67),\n",
       " ('pre', 66),\n",
       " ('Plan', 66),\n",
       " ('pullback', 66),\n",
       " ('strength', 66),\n",
       " ('continues', 66),\n",
       " ('Jaffray', 66),\n",
       " ('YHOO', 66),\n",
       " ('FIVE', 66),\n",
       " ('Upgrades', 66),\n",
       " ('wants', 66),\n",
       " ('Buying', 65),\n",
       " ('consensus', 65),\n",
       " ('likely', 65),\n",
       " ('DPS', 65),\n",
       " ('given', 65),\n",
       " ('least', 65),\n",
       " ('Vol', 65),\n",
       " ('Futures', 64),\n",
       " ('bulls', 64),\n",
       " ('XRT', 64),\n",
       " ('Group', 64),\n",
       " ('side', 63),\n",
       " ('started', 63),\n",
       " ('neutral', 63),\n",
       " ('upgrades', 63),\n",
       " ('quick', 63),\n",
       " ('Your', 63),\n",
       " ('baby', 63),\n",
       " ('James', 62),\n",
       " ('something', 62),\n",
       " ('expected', 62),\n",
       " ('enough', 62),\n",
       " ('Thanks', 62),\n",
       " ('finally', 62),\n",
       " ('Did', 61),\n",
       " ('wonder', 61),\n",
       " ('increase', 61),\n",
       " (\"'d\", 61),\n",
       " ('based', 61),\n",
       " ('fb', 61),\n",
       " ('Very', 61),\n",
       " ('show', 61),\n",
       " ('key', 61),\n",
       " ('Deutsche', 61),\n",
       " ('AMBA', 60),\n",
       " ('push', 60),\n",
       " ('Shares', 60),\n",
       " ('bet', 60),\n",
       " ('avg', 60),\n",
       " ('thinking', 60),\n",
       " ('COH', 60),\n",
       " ('cut', 60),\n",
       " ('Retail', 60),\n",
       " ('WFM', 60),\n",
       " ('luck', 60),\n",
       " ('possible', 59),\n",
       " ('flat', 59),\n",
       " ('adding', 59),\n",
       " ('Morgan', 59),\n",
       " ('Orders', 59),\n",
       " ('pattern', 59),\n",
       " ('business', 59),\n",
       " ('Jefferies', 59),\n",
       " ('cashed-in', 58),\n",
       " ('chance', 58),\n",
       " ('World', 58),\n",
       " ('spy', 58),\n",
       " ('else', 58),\n",
       " ('momentum', 58),\n",
       " ('Wow', 58),\n",
       " ('PE', 58),\n",
       " ('saying', 58),\n",
       " ('distribution', 58),\n",
       " ('0.00', 58),\n",
       " ('mean', 57),\n",
       " ('old', 57),\n",
       " ('Would', 57),\n",
       " ('plays', 57),\n",
       " ('sneaker', 57),\n",
       " ('Zacks', 57),\n",
       " ('upgraded', 57),\n",
       " ('Only', 57),\n",
       " ('Share', 57),\n",
       " ('POS', 57),\n",
       " ('sign', 57),\n",
       " ('release', 57),\n",
       " ('Beat', 57),\n",
       " ('View', 57),\n",
       " ('JBLU', 57),\n",
       " ('playing', 56),\n",
       " ('Published', 56),\n",
       " ('compared', 56),\n",
       " ('JBL', 56),\n",
       " ('Capital', 56),\n",
       " ('Anyone', 56),\n",
       " ('showing', 56),\n",
       " ('products', 56),\n",
       " ('thoughts', 56),\n",
       " ('Athletic', 56),\n",
       " ('buys', 56),\n",
       " ('premarket', 56),\n",
       " ('There', 56),\n",
       " ('damn', 56),\n",
       " ('One', 56),\n",
       " ('Charts', 56),\n",
       " ('wear', 55),\n",
       " ('SCTY', 55),\n",
       " ('Maybe', 55),\n",
       " ('LT', 55),\n",
       " ('LNKD', 55),\n",
       " ('rest', 55),\n",
       " ('thanks', 55),\n",
       " ('minutes', 55),\n",
       " ('order', 55),\n",
       " ('X', 55),\n",
       " ('told', 55),\n",
       " ('Free', 55),\n",
       " ('Footwear', 54),\n",
       " ('lt', 54),\n",
       " ('Go', 54),\n",
       " ('weakness', 54),\n",
       " ('YTD', 54),\n",
       " ('sports', 54),\n",
       " ('Another', 54),\n",
       " ('UVXY', 54),\n",
       " ('Shoe', 54),\n",
       " ('test', 53),\n",
       " ('buyers', 53),\n",
       " ('pick', 53),\n",
       " ('dont', 53),\n",
       " ('someone', 53),\n",
       " ('America', 53),\n",
       " ('crazy', 53),\n",
       " ('bears', 53),\n",
       " ('broken', 53),\n",
       " ('Rating', 53),\n",
       " ('movement', 53),\n",
       " ('Bulls', 53),\n",
       " ('Rated', 53),\n",
       " ('NKE/', 53),\n",
       " ('cap', 52),\n",
       " ('decent', 52),\n",
       " ('OI', 52),\n",
       " ('spread', 52),\n",
       " ('work', 52),\n",
       " ('COLM', 52),\n",
       " ('falling', 52),\n",
       " ('UP', 52),\n",
       " ('cover', 52),\n",
       " ('conference', 52),\n",
       " ('Credit', 52),\n",
       " ('couple', 52),\n",
       " ('happen', 52),\n",
       " ('guy', 52),\n",
       " ('anything', 52),\n",
       " ('Quarter', 51),\n",
       " ('happy', 51),\n",
       " ('w', 51),\n",
       " ('posted', 51),\n",
       " ('Higher', 51),\n",
       " ('find', 51),\n",
       " ('drops', 51),\n",
       " ('comp', 51),\n",
       " ('happens', 51),\n",
       " ('mkt', 51),\n",
       " ('keeps', 51),\n",
       " ('EOD', 51),\n",
       " ('weekend', 51),\n",
       " ('Full', 51),\n",
       " ('offer', 51),\n",
       " ('Company', 50),\n",
       " ('jump', 50),\n",
       " ('reporting', 50),\n",
       " ('story', 50),\n",
       " ('hits', 50),\n",
       " ('thought', 50),\n",
       " ('Portfolio', 50),\n",
       " ('Does', 50),\n",
       " ('dips', 50),\n",
       " ('buyer', 50),\n",
       " ('seeing', 50),\n",
       " ('hoping', 50),\n",
       " ('mid', 50),\n",
       " ('SONC', 50),\n",
       " ('Line', 50),\n",
       " ('success', 50),\n",
       " ('traders', 49),\n",
       " ('PIR', 49),\n",
       " ('activity', 49),\n",
       " ('brands', 49),\n",
       " ('reported', 49),\n",
       " ('Early', 49),\n",
       " ('investment', 49),\n",
       " ('shorting', 49),\n",
       " ('head', 49),\n",
       " ('channel', 49),\n",
       " ('ATH', 49),\n",
       " ('oil', 49),\n",
       " ('heading', 48),\n",
       " ('held', 48),\n",
       " ('IMO', 48),\n",
       " ('bell', 48),\n",
       " ('lots', 48),\n",
       " ('picked', 48),\n",
       " ('Sterne', 48),\n",
       " ('GME', 48),\n",
       " ('technical', 48),\n",
       " ('oh', 48),\n",
       " ('moves', 48),\n",
       " ('forward', 48),\n",
       " ('closing', 48),\n",
       " ('less', 48),\n",
       " ('tell', 48),\n",
       " ('imbalances', 48),\n",
       " ('SWHC', 48),\n",
       " ('outperform', 48),\n",
       " ('PANW', 48),\n",
       " ('along', 48),\n",
       " ('cant', 48),\n",
       " ('seen', 47),\n",
       " ('Also', 47),\n",
       " ('article', 47),\n",
       " ('ideas', 47),\n",
       " ('traded', 47),\n",
       " ('Stanley', 47),\n",
       " ('earlier', 47),\n",
       " ('wish', 47),\n",
       " ('Love', 47),\n",
       " ('Agee', 47),\n",
       " ('return', 47),\n",
       " ('Got', 47),\n",
       " ('Goldman', 47),\n",
       " ('full', 47),\n",
       " ('area', 47),\n",
       " ('currency', 47),\n",
       " ('Suisse', 47),\n",
       " ('wearing', 47),\n",
       " ('all-time', 47),\n",
       " ('Interactive', 47),\n",
       " ('ApparelAndAccessories', 47),\n",
       " ('RAD', 46),\n",
       " ('total', 46),\n",
       " ('Canaccord', 46),\n",
       " ('growing', 46),\n",
       " ('room', 46),\n",
       " ('FEYE', 46),\n",
       " ('Even', 46),\n",
       " ('fit', 46),\n",
       " ('Bearish', 46),\n",
       " ('golf', 46),\n",
       " ('Or', 46),\n",
       " ('Steph', 46),\n",
       " ('Tomorrow', 46),\n",
       " ('actually', 45),\n",
       " ('broke', 45),\n",
       " ('called', 45),\n",
       " ('footwear', 45),\n",
       " ('left', 45),\n",
       " ('global', 45),\n",
       " ('holds', 45),\n",
       " ('times', 45),\n",
       " ('folks', 45),\n",
       " ('latest', 45),\n",
       " ('Markets', 45),\n",
       " ('BUYING', 45),\n",
       " ('fade', 45),\n",
       " ('Added', 45),\n",
       " ('sense', 45),\n",
       " ('AGN', 45),\n",
       " ('Jones', 45),\n",
       " ('Ca', 45),\n",
       " ('0.51', 45),\n",
       " ('pain', 44),\n",
       " ('GLD', 44),\n",
       " ('ES_F', 44),\n",
       " ('late', 44),\n",
       " ('Well', 44),\n",
       " ('Potential', 44),\n",
       " ('biggest', 44),\n",
       " ('futures', 44),\n",
       " ('adidas', 43),\n",
       " ('things', 43),\n",
       " ('Momentum', 43),\n",
       " ('read', 43),\n",
       " ('margin', 43),\n",
       " ('Need', 43),\n",
       " ('product', 43),\n",
       " ('thinks', 43),\n",
       " ('check', 43),\n",
       " ('cost', 43),\n",
       " ('Trades', 43),\n",
       " ('priced', 43),\n",
       " ('Skechers', 43),\n",
       " ('Breakout', 43),\n",
       " ('U.S.', 43),\n",
       " ('Like', 43),\n",
       " ('THE', 43),\n",
       " ('talk', 42),\n",
       " ('FSLR', 42),\n",
       " ('Options', 42),\n",
       " ('athletic', 42),\n",
       " ('Better', 42),\n",
       " ('Cash', 42),\n",
       " ('Current', 42),\n",
       " ('major', 42),\n",
       " ('TLT', 42),\n",
       " ('Im', 42),\n",
       " ('pos', 42),\n",
       " ('boost', 42),\n",
       " ('following', 42),\n",
       " ('CC', 42),\n",
       " ('pair', 42),\n",
       " ('IPO', 42),\n",
       " ('Durant', 42),\n",
       " ('funny', 42),\n",
       " ('points', 41),\n",
       " ('free', 41),\n",
       " ('Lol', 41),\n",
       " ('Quarterly', 41),\n",
       " ('competition', 41),\n",
       " ('AM', 41),\n",
       " ('Christmas', 41),\n",
       " ('losing', 41),\n",
       " ('fast', 41),\n",
       " ('later', 41),\n",
       " ('comes', 41),\n",
       " ('either', 41),\n",
       " ('nflx', 41),\n",
       " ('opinion', 41),\n",
       " ('VXX', 41),\n",
       " ('Nke', 41),\n",
       " ('BUD', 41),\n",
       " ('Highs', 41),\n",
       " ('Deal', 41),\n",
       " ('load', 41),\n",
       " ('Game', 40),\n",
       " ('ok', 40),\n",
       " ('cool', 40),\n",
       " ('Was', 40),\n",
       " ('People', 40),\n",
       " ('bot', 40),\n",
       " ('winners', 40),\n",
       " ('USD', 40),\n",
       " ('others', 40),\n",
       " ('Bears', 40),\n",
       " ('Foot', 40),\n",
       " ('Lululemon', 40),\n",
       " ('Waiting', 40),\n",
       " ('valuation', 40),\n",
       " ('Says', 40),\n",
       " ('tax', 40),\n",
       " ('Fitbit', 40),\n",
       " ('ride', 40),\n",
       " ('headed', 40),\n",
       " ('rev', 40),\n",
       " ('pay', 40),\n",
       " ('Oh', 40),\n",
       " ('Large', 40),\n",
       " ('Highest', 40),\n",
       " ('Move', 39),\n",
       " ('surprised', 39),\n",
       " ('Lower', 39),\n",
       " ('Post', 39),\n",
       " ('surprise', 39),\n",
       " ('Hope', 39),\n",
       " ('swoosh', 39),\n",
       " ('tech', 39),\n",
       " ('downgrades', 39),\n",
       " ('working', 39),\n",
       " ('place', 39),\n",
       " ('rumor', 39),\n",
       " ('retailers', 39),\n",
       " ('kids', 39),\n",
       " ('GMCR', 39),\n",
       " ('maintained', 39),\n",
       " ('Following', 39),\n",
       " ('candle', 39),\n",
       " ('Keep', 39),\n",
       " ('Where', 39),\n",
       " ('Valuation', 39),\n",
       " ('Huge', 39),\n",
       " ('Cap', 39),\n",
       " ('UWTI', 39),\n",
       " ('YELP', 38),\n",
       " ('hot', 38),\n",
       " ('invest', 38),\n",
       " ('percent', 38),\n",
       " ('amzn', 38),\n",
       " ('number', 38),\n",
       " ('watchlist', 38),\n",
       " ('UTX', 38),\n",
       " ('glad', 38),\n",
       " ('sentiment', 38),\n",
       " ('Locker', 38),\n",
       " ('downgrade', 38),\n",
       " ('clear', 38),\n",
       " ('everything', 38),\n",
       " ('rising', 38),\n",
       " ('night', 38),\n",
       " ('–', 38),\n",
       " ('End', 38),\n",
       " ('RAI', 38),\n",
       " ('Low', 38),\n",
       " ('Hourly', 38),\n",
       " ('crap', 38),\n",
       " ('Fiscal', 37),\n",
       " ('Getting', 37),\n",
       " ('downgraded', 37),\n",
       " ('similar', 37),\n",
       " ('Morning', 37),\n",
       " ('case', 37),\n",
       " ('8-K', 37),\n",
       " ('qtr', 37),\n",
       " ('talking', 37),\n",
       " ('revenues', 37),\n",
       " ('intraday', 37),\n",
       " ('million', 37),\n",
       " ('data', 37),\n",
       " ('Over', 37),\n",
       " ('industry', 37),\n",
       " ('sbux', 37),\n",
       " ('Too', 37),\n",
       " ('update', 37),\n",
       " ('Swoosh', 37),\n",
       " ('behind', 37),\n",
       " ('expensive', 37),\n",
       " ('Recap', 37),\n",
       " ('vol', 37),\n",
       " ('Hold', 37),\n",
       " ('VIPS', 37),\n",
       " ('Sachs', 37),\n",
       " ('CHK', 37),\n",
       " ('buyback', 37),\n",
       " ('Tiger', 36),\n",
       " ('Announces', 36),\n",
       " ('Cup', 36),\n",
       " ...]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check which words occur most frequently and discover any data that needs to be filtered\n",
    "sorted(word_dict.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = list(word_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alter dataframe such that the posts in a given day form one document and then determine tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A lot of stocks now trading green:  $GS $WFC $JPM $PG $KO $TRV $VZ $XOM $CVX $NKE $PM $CLX $MCD'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_nke['body'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(wordlist, word_features):\n",
    "    data = {}\n",
    "    #laplace smoothing numerator\n",
    "    data = data.fromkeys(word_features,0)\n",
    "    for feature in word_features:\n",
    "        for word in wordlist:\n",
    "            if feature == word:\n",
    "                data[feature] = data.get(feature) + 1\n",
    "    #for key in data:\n",
    "        #laplace smoothing denominator\n",
    "        #data[key] = data.get(key)/(len(wordlist)+2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_tf_dataframe(text, word_features):    \n",
    "    dates = list(set(list(text['date'])))\n",
    "    dates.sort()\n",
    "    text_dictbydate = []\n",
    "    for i in range(0, len(dates)):\n",
    "        temp = text[text['date'] == dates[i]]['body']\n",
    "        b = []\n",
    "        for string in temp:\n",
    "            a = word_tokenize(string)\n",
    "            b = b + a\n",
    "        text_dictbydate.append(tf(b, word_features))\n",
    "    df_tf = pd.DataFrame(data=text_dictbydate)\n",
    "    #df_tf['date'] = dates\n",
    "    date_df = pd.DataFrame({'date': dates})\n",
    "    df_tf = pd.concat([date_df, df_tf], axis=1)\n",
    "    return df_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lot</th>\n",
       "      <th>stocks</th>\n",
       "      <th>trading</th>\n",
       "      <th>green</th>\n",
       "      <th>EVP</th>\n",
       "      <th>CFO</th>\n",
       "      <th>cashed-in</th>\n",
       "      <th>options</th>\n",
       "      <th>China</th>\n",
       "      <th>...</th>\n",
       "      <th>Brean</th>\n",
       "      <th>DWTI</th>\n",
       "      <th>lights</th>\n",
       "      <th>7x</th>\n",
       "      <th>5x</th>\n",
       "      <th>E2</th>\n",
       "      <th>https</th>\n",
       "      <th>NKE/</th>\n",
       "      <th>ApparelAndAccessories</th>\n",
       "      <th>0.51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2013-12-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2013-12-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2013-12-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1077</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1078</td>\n",
       "      <td>2016-12-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1079</td>\n",
       "      <td>2016-12-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>2016-12-04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1081</td>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1082 rows × 1483 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  lot  stocks  trading  green  EVP  CFO  cashed-in  options  \\\n",
       "0    2013-12-03    1       1        1      1    1    1          1        1   \n",
       "1    2013-12-04    1       0        0      0    0    0          0        0   \n",
       "2    2013-12-05    0       0        0      0    0    0          0        0   \n",
       "3    2013-12-06    0       0        0      0    0    0          0        0   \n",
       "4    2013-12-07    0       0        0      0    0    0          0        0   \n",
       "...         ...  ...     ...      ...    ...  ...  ...        ...      ...   \n",
       "1077 2016-12-01    0       0        0      0    0    0          0        0   \n",
       "1078 2016-12-02    0       1        0      1    0    0          0        1   \n",
       "1079 2016-12-03    0       0        0      0    0    0          0        0   \n",
       "1080 2016-12-04    0       1        0      0    0    0          0        1   \n",
       "1081 2016-12-05    1       3        1      2    0    0          0        0   \n",
       "\n",
       "      China  ...  Brean  DWTI  lights  7x  5x  E2  https  NKE/  \\\n",
       "0         0  ...      0     0       0   0   0   0      0     0   \n",
       "1         1  ...      0     0       0   0   0   0      0     0   \n",
       "2         0  ...      0     0       0   0   0   0      0     0   \n",
       "3         0  ...      0     0       0   0   0   0      0     0   \n",
       "4         0  ...      0     0       0   0   0   0      0     0   \n",
       "...     ...  ...    ...   ...     ...  ..  ..  ..    ...   ...   \n",
       "1077      0  ...      0     0       1   0   0   0      2     0   \n",
       "1078      0  ...      0     0       0   0   0   0      3     0   \n",
       "1079      0  ...      0     0       0   0   0   0      1     0   \n",
       "1080      0  ...      0     0       0   0   0   0      0     0   \n",
       "1081      0  ...      0     0       0   0   3   0     12     0   \n",
       "\n",
       "      ApparelAndAccessories  0.51  \n",
       "0                         0     0  \n",
       "1                         0     0  \n",
       "2                         0     0  \n",
       "3                         0     0  \n",
       "4                         0     0  \n",
       "...                     ...   ...  \n",
       "1077                      0     0  \n",
       "1078                      0     0  \n",
       "1079                      0     0  \n",
       "1080                      0     0  \n",
       "1081                      1     0  \n",
       "\n",
       "[1082 rows x 1483 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf = get_tf_dataframe(text_nke, word_features)\n",
    "df_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf(text, word_features):    \n",
    "    dates = list(set(list(text['date'])))\n",
    "    dates.sort()\n",
    "    \n",
    "    idf = {}\n",
    "    idf = idf.fromkeys(word_features, 1)\n",
    "    \n",
    "    for i in range(0, len(dates)):\n",
    "        temp = text[text['date'] == dates[i]]['body']\n",
    "        b = []\n",
    "        for string in temp:\n",
    "            a = word_tokenize(string)\n",
    "            b = b + a\n",
    "        for word in word_features:\n",
    "            if word in b:\n",
    "                idf[word] = idf.get(word)+1\n",
    "    for key in idf:\n",
    "        idf[key] = np.log(len(dates)/idf.get(key))\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#obtain idf values for features\n",
    "dict_idf = get_idf(text_nke, word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.062310661991895"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this value makes sense as we can see that the word earnings appears most frequently (not in terms of number of docs)\n",
    "#but in terms of absolute frequency\n",
    "#from this, a low log(Corpus volume/number of docs where earnings occurs) should be relatively low\n",
    "dict_idf['earnings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date  a  b  c\n",
      "0  1000  3 -1  5\n",
      "1  2000 -1  1  4\n"
     ]
    }
   ],
   "source": [
    "#test out something\n",
    "temp = [{'a': 3, 'b': -1, 'c': 5}, {'a': -1, 'b': 1, 'c': 4}]\n",
    "dates = {'date': [1000, 2000]}\n",
    "dates = pd.DataFrame(dates)\n",
    "frog = pd.DataFrame(temp)\n",
    "df_temp = pd.concat([dates, frog], axis=1)\n",
    "print(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(df_tf, dict_idf):\n",
    "    tfidf = df_tf\n",
    "    for key in dict_idf:\n",
    "        tfidf[key] = tfidf[key].apply(lambda x: x*dict_idf.get(key))\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lot</th>\n",
       "      <th>stocks</th>\n",
       "      <th>trading</th>\n",
       "      <th>green</th>\n",
       "      <th>EVP</th>\n",
       "      <th>CFO</th>\n",
       "      <th>cashed-in</th>\n",
       "      <th>options</th>\n",
       "      <th>China</th>\n",
       "      <th>...</th>\n",
       "      <th>Brean</th>\n",
       "      <th>DWTI</th>\n",
       "      <th>lights</th>\n",
       "      <th>7x</th>\n",
       "      <th>5x</th>\n",
       "      <th>E2</th>\n",
       "      <th>https</th>\n",
       "      <th>NKE/</th>\n",
       "      <th>ApparelAndAccessories</th>\n",
       "      <th>0.51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>2.655833</td>\n",
       "      <td>1.212015</td>\n",
       "      <td>1.956129</td>\n",
       "      <td>2.134536</td>\n",
       "      <td>3.942044</td>\n",
       "      <td>4.153353</td>\n",
       "      <td>3.094746</td>\n",
       "      <td>1.89897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2013-12-04</td>\n",
       "      <td>2.655833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.371446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2013-12-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2013-12-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1483 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date       lot    stocks   trading     green       EVP       CFO  \\\n",
       "0 2013-12-03  2.655833  1.212015  1.956129  2.134536  3.942044  4.153353   \n",
       "1 2013-12-04  2.655833  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2 2013-12-05  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3 2013-12-06  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4 2013-12-07  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "   cashed-in  options     China  ...  Brean  DWTI  lights   7x   5x   E2  \\\n",
       "0   3.094746  1.89897  0.000000  ...    0.0   0.0     0.0  0.0  0.0  0.0   \n",
       "1   0.000000  0.00000  2.371446  ...    0.0   0.0     0.0  0.0  0.0  0.0   \n",
       "2   0.000000  0.00000  0.000000  ...    0.0   0.0     0.0  0.0  0.0  0.0   \n",
       "3   0.000000  0.00000  0.000000  ...    0.0   0.0     0.0  0.0  0.0  0.0   \n",
       "4   0.000000  0.00000  0.000000  ...    0.0   0.0     0.0  0.0  0.0  0.0   \n",
       "\n",
       "   https  NKE/  ApparelAndAccessories  0.51  \n",
       "0    0.0   0.0                    0.0   0.0  \n",
       "1    0.0   0.0                    0.0   0.0  \n",
       "2    0.0   0.0                    0.0   0.0  \n",
       "3    0.0   0.0                    0.0   0.0  \n",
       "4    0.0   0.0                    0.0   0.0  \n",
       "\n",
       "[5 rows x 1483 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtain the final TFIDF dataframe\n",
    "df_tfidf = get_tfidf(df_tf, dict_idf)\n",
    "df_tfidf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Naive Bayes Classifiction***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare DataFrame for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_metricsandvalue[['Date', 'rt3', 'rt5']][:823]\n",
    "df_target.columns = ['date', 'rt3', 'rt5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df_target['rt3'][df_target['rt3'] > 0] = 1\n",
    "df_target['rt3'][df_target['rt3'] <= 0] = 0\n",
    "df_target['rt5'][df_target['rt5'] > 0] = 1\n",
    "df_target['rt5'][df_target['rt5'] <= 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(753, 1485)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf['date'] = pd.to_datetime(df_tfidf['date'])\n",
    "df_target['date'] = pd.to_datetime(df_target['date'])\n",
    "df_merge = pd.merge(df_tfidf, df_target, on='date', how='inner')\n",
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "753"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirms that the merge worked\n",
    "targetdate = list(df_target['date'])\n",
    "tfidfdate = list(df_tfidf['date'])\n",
    "len(set(targetdate) & set(tfidfdate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= list(df_merge.columns)\n",
    "features.remove('date')\n",
    "features.remove('rt3')\n",
    "features.remove('rt5')\n",
    "rt3features = sklearn.feature_selection.chi2(df_merge[features], df_merge['rt3'])\n",
    "rt5features = sklearn.feature_selection.chi2(df_merge[features], df_merge['rt5'])\n",
    "rt3selected = []\n",
    "rt5selected = []\n",
    "for i in range(0,len(features)):\n",
    "    if rt3features[1][i] < 0.1:\n",
    "        rt3selected.append(features[i])\n",
    "    if rt5features[1][i] < 0.1:\n",
    "        rt5selected.append(features[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "lendf = len(df_merge)\n",
    "crit = int(np.floor(lendf*2/3))\n",
    "df_train = df_merge[:crit]\n",
    "df_test = df_merge[crit:]\n",
    "\n",
    "#extract train x and y\n",
    "xrt3_train = df_train[rt3selected]\n",
    "xrt5_train = df_train[rt5selected]\n",
    "yrt3_train = df_train['rt3']\n",
    "yrt5_train = df_train['rt5']\n",
    "\n",
    "#extract test x and y\n",
    "xrt3_test = df_test[rt3selected]\n",
    "xrt5_test = df_test[rt5selected]\n",
    "yrt3_test = df_test['rt3']\n",
    "yrt5_test = df_test['rt5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GNB(xfit, yfit, xpred, ypred):\n",
    "    #fit NB based on parameter\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(xfit, yfit)\n",
    "    \n",
    "    #predict based on parameter\n",
    "    y_pred = gnb.predict(xpred)\n",
    "    ylist = list(ypred)\n",
    "    ypredlist = list(y_pred)\n",
    "    count = 0\n",
    "    for i in range(0, len(ypredlist)):\n",
    "        if ylist[i] == ypredlist[i]:\n",
    "            count = count + 1\n",
    "    print('Accuracy:', count/len(ypredlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Accuracy for rt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7270916334661355\n"
     ]
    }
   ],
   "source": [
    "GNB(xrt3_train, yrt3_train, xrt3_train, yrt3_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Accuracy for rt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6175298804780877\n"
     ]
    }
   ],
   "source": [
    "GNB(xrt5_train, yrt5_train, xrt5_train, yrt5_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Accuracy for rt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5258964143426295\n"
     ]
    }
   ],
   "source": [
    "GNB(xrt3_train, yrt3_train, xrt3_test, yrt3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Accuracy for rt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4701195219123506\n"
     ]
    }
   ],
   "source": [
    "GNB(xrt5_train, yrt5_train, xrt5_test, yrt5_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Logistic Regression***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(743, 1490)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf['date'] = pd.to_datetime(df_tfidf['date'])\n",
    "df_volume['date'] = pd.to_datetime(df_volume['date'])\n",
    "df_target['date'] = pd.to_datetime(df_target['date'])\n",
    "df_temp = pd.merge(df_tfidf, df_volume, on='date', how='inner')\n",
    "df_merge = pd.merge(df_temp, df_target, on='date', how='inner')\n",
    "df_merge = df_merge[10:]\n",
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = ['st', 'mv1t', 'mv10t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "lendf = len(df_merge)\n",
    "crit = int(np.floor(lendf*2/3))\n",
    "df_train = df_merge[:crit]\n",
    "df_test = df_merge[crit:]\n",
    "\n",
    "#extract train x and y\n",
    "xrt3_train = df_train[rt3selected + add]\n",
    "xrt5_train = df_train[rt5selected + add]\n",
    "yrt3_train = df_train['rt3']\n",
    "yrt5_train = df_train['rt5']\n",
    "\n",
    "#extract test x and y\n",
    "xrt3_test = df_test[rt3selected + add]\n",
    "xrt5_test = df_test[rt5selected + add]\n",
    "yrt3_test = df_test['rt3']\n",
    "yrt5_test = df_test['rt5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticreg_accuracy(x_train, y_train, x_test, y_test):   \n",
    "    clf = LogisticRegression().fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    ypredlist = list(y_pred)\n",
    "    ytestlist = list(y_test)\n",
    "    count = 0\n",
    "    for i in range(0, len(ypredlist)):\n",
    "        if ypredlist[i] == ytestlist[i]:\n",
    "            count = count+1\n",
    "    print(count/len(ypredlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train error for rt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997979797979798\n"
     ]
    }
   ],
   "source": [
    "logisticreg_accuracy(xrt3_train, yrt3_train, xrt3_train, yrt3_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test error for rt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4959677419354839\n"
     ]
    }
   ],
   "source": [
    "logisticreg_accuracy(xrt3_train, yrt3_train, xrt3_test, yrt3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train error for rt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "logisticreg_accuracy(xrt5_train, yrt5_train, xrt5_train, yrt5_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test error for rt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4475806451612903\n"
     ]
    }
   ],
   "source": [
    "logisticreg_accuracy(xrt5_train, yrt5_train, xrt5_test, yrt5_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
